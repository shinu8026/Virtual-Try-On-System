{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Try-On System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentor(image_path):\n",
    "\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Preprocessing\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)  # Apply Gaussian blur\n",
    "\n",
    "    # Segmentation (using GrabCut)\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    rect = (50, 50, 450, 450)  # Initial rectangle for GrabCut\n",
    "    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    img_segmented = img * mask2[:, :, np.newaxis]\n",
    "\n",
    "    # Clothing detection (using a pre-trained YOLOv5 model)\n",
    "    # model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "    # results = model(img_segmented)\n",
    "\n",
    "    cv2.imshow(\"Segmented Image\", img_segmented)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return img_segmented\n",
    "\n",
    "# Initialize MediaPipe's pose detection model\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def try_on_clothing(user_image, clothing_image):\n",
    "\n",
    "    # Create a mask for the user's body\n",
    "    body_mask = np.zeros(user_image.shape[:2], np.uint8)\n",
    "    \n",
    "    # Initialize the pose detection model\n",
    "    pose_model = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.8)\n",
    "    \n",
    "    # Process the user image to get pose landmarks\n",
    "    pose_results = pose_model.process(cv2.cvtColor(user_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Extract landmarks for left and right shoulders, and left and right hips\n",
    "    left_shoulder_user = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "    right_shoulder_user = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "    left_foot_user = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_FOOT_INDEX]\n",
    "    right_foot_user = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX]\n",
    "\n",
    "    # Convert the landmarks to image coordinates\n",
    "    image_height, image_width, _ = user_image.shape\n",
    "    left_shoulder_user_x, left_shoulder_user_y = int(left_shoulder_user.x * image_width), int(left_shoulder_user.y * image_height)\n",
    "    right_shoulder_user_x, right_shoulder_user_y = int(right_shoulder_user.x * image_width), int(right_shoulder_user.y * image_height)\n",
    "    left_foot_user_x, left_foot_user_y = int(left_foot_user.x * image_width), int(left_foot_user.y * image_height)\n",
    "    right_foot_user_x, right_foot_user_y = int(right_foot_user.x * image_width), int(right_foot_user.y * image_height)\n",
    "\n",
    "    # Calculate the size of the clothing image based on the user's pose\n",
    "    shoulder_width_user = abs(right_shoulder_user_x - left_shoulder_user_x)\n",
    "    foot_width_user = abs(right_foot_user_x - left_foot_user_x)\n",
    "    \n",
    "    # Resize the clothing image to fit the user's torso\n",
    "    clothing_image_resized = cv2.resize(clothing_image, (shoulder_width_user, foot_width_user))\n",
    "\n",
    "    # Define the corners of the region to be replaced with the clothing image\n",
    "    # source points\n",
    "    src_pts = np.array([[0, 0],\n",
    "                        [shoulder_width_user, 0],\n",
    "                        [shoulder_width_user, foot_width_user],\n",
    "                        [0, foot_width_user]], dtype=np.float32)\n",
    "    \n",
    "    # Destination points\n",
    "    dst_pts = np.array([[left_shoulder_user_x, left_shoulder_user_y],\n",
    "                        [right_shoulder_user_x, right_shoulder_user_y],\n",
    "                        [right_foot_user_x, right_foot_user_y],\n",
    "                        [left_foot_user_x, left_foot_user_y]], dtype=np.float32)\n",
    "\n",
    "    # Get the perspective transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "\n",
    "    # Warp the clothing image onto the user image\n",
    "    warped_clothing = cv2.warpPerspective(clothing_image_resized, M, (image_width, image_height))\n",
    "\n",
    "    # Create a mask of the region to be replaced with the clothing image\n",
    "    mask = np.zeros_like(user_image)\n",
    "    cv2.fillPoly(mask, [np.int32(dst_pts)], (255, 255, 255))\n",
    "\n",
    "    # Invert the mask\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Extract the region from the user image that will be replaced\n",
    "    user_image_region = cv2.bitwise_and(user_image, mask_inv)\n",
    "\n",
    "    # Blend the clothing image with the user image\n",
    "    final_image = cv2.add(warped_clothing, user_image_region)\n",
    "\n",
    "    # Display the final image\n",
    "    cv2.imshow(\"Virtual Try-On\", final_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_image_path = r\"C:\\Users\\shish\\OneDrive\\Documents\\GitHub\\Virtual_wardrobe_recommender_system\\lady.jpeg\"\n",
    "clothing_image_path = r\"C:\\Users\\shish\\OneDrive\\Documents\\GitHub\\Virtual_wardrobe_recommender_system\\clothing.jpg\"\n",
    "\n",
    "user_image = segmentor(user_image_path)\n",
    "clothing_image = segmentor(clothing_image_path)\n",
    "\n",
    "try_on_clothing(user_image, clothing_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
